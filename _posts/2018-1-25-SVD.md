---
layout : post
title : Singular Value Decomposition
desc : <div class="tag">Linear Algebra</div><div class="tag">Dimesnionality Reduction</div><br>
img  : ../public/post-assets/SVD/matrix-factorization.png
---

**Content:**
<!-- MarkdownTOC depth=4 -->

- [SVD](#svd)

<!-- /MarkdownTOC -->

basis for row space : v1
basis for col space : u1

Av1 = sigma u1 (same number of basic cuz number of basis for row space = no of basis for col space = rank )
=> AV  = ZU (U and V and Z max length = r, now we need to extend it to m)

A^TA = V Z^2 V^T. A^TA is symetric so it can be diagonalizaed (spectral theorem) -> V is eigenvectors of A^TA, they are orthonormal vector. Same for U.


NOW HOW TO FILL UP THE REST OF VECTOR TO COMPLETE SVD?
IS THIS A LEGIT PROOF FOR EXISTENCE OF SVD?

<a name="svd"></a>
### SVD 

Suppose we know the (proved fact)[add link] that every square matrix can be factorized into the product of 3 special matrixed. 

We call v1 is a vector in row space. So Av_1 will be the linear combination of collumn vectors in A, the coefficients is elements in v_1. This combination of collumn vector in A creates a new vector in collumn space of A. -> Av1 = sigma u1, we take v1...v_r : basis of row space and we get AV=UZ (not ZU) bc number of basis for col space and row space are equal, now need to prove that U is also orthornomal providing that V is orthornormal basis of row space.

multiply both side with V^T => A = UZV^T
A^TA = VZ^T U^T UZV^T = V Z^2 V^T


Proof that U is orthogonal matrix: 
v1, v2 are orthogonal vector => v1 v2^T = 0 
u1.u2 (dot product) = Av1.v2^T A^T = 0


=>
A^T A V = VZ^2

=> A^TA v_i = z_i^2 v_i

=> v_i is eigen... (sometime it doesnt exist but A^TA is symetric positive definite matrix)
